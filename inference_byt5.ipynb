{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Past Challenge: ByT5 Inference\n",
    "\n",
    "Kaggle submission notebook. Loads the fine-tuned ByT5 model and generates translations.\n",
    "\n",
    "**Requirements**:\n",
    "- Add your trained model as a Kaggle dataset (e.g. `your-username/byt5-akkadian-final`)\n",
    "- No internet access needed (offline inference)\n",
    "- Must complete within 9 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# Configuration\n# ============================================================\nIS_KAGGLE = os.path.exists(\"/kaggle/input\")\n\nif IS_KAGGLE:\n    COMP_DATA = \"/kaggle/input/deep-past-initiative-machine-translation\"\n    # Trained model uploaded as Kaggle dataset\n    MODEL_PATH = \"/kaggle/input/byt5-akkadian-final\"\nelse:\n    COMP_DATA = \"data\"\n    MODEL_PATH = \"trained_model/byt5_stage2_final\"\n\nPREFIX = \"translate Akkadian to English: \"\nMAX_SOURCE_LEN = 384\nMAX_TARGET_LEN = 384\nBEAM_WIDTH = 4\nREP_PENALTY = 1.2\nBATCH_SIZE = 16"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Configuration\n",
    "# ============================================================\n",
    "IS_KAGGLE = os.path.exists(\"/kaggle/input\")\n",
    "\n",
    "if IS_KAGGLE:\n",
    "    COMP_DATA = \"/kaggle/input/deep-past-initiative-machine-translation\"\n",
    "    # Update this to your uploaded model dataset path:\n",
    "    MODEL_PATH = \"/kaggle/input/byt5-akkadian-final/byt5_stage2_final\"\n",
    "else:\n",
    "    COMP_DATA = \"data\"\n",
    "    MODEL_PATH = \"output/byt5_stage2_final\"\n",
    "\n",
    "PREFIX = \"translate Akkadian to English: \"\n",
    "MAX_SOURCE_LEN = 512\n",
    "MAX_TARGET_LEN = 512\n",
    "BEAM_WIDTH = 4\n",
    "REP_PENALTY = 1.2\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Preprocessing (must match training)\n",
    "# ============================================================\n",
    "SUBSCRIPT_MAP = str.maketrans(\"\\u2080\\u2081\\u2082\\u2083\\u2084\\u2085\\u2086\\u2087\\u2088\\u2089\",\n",
    "                              \"0123456789\")\n",
    "\n",
    "ASCII_TO_DIACRITIC = {\n",
    "    \"sz\": \"\\u0161\", \"SZ\": \"\\u0160\", \"Sz\": \"\\u0160\",\n",
    "    \"sh\": \"\\u0161\", \"SH\": \"\\u0160\", \"Sh\": \"\\u0160\",\n",
    "    \"s,\": \"\\u1E63\", \"S,\": \"\\u1E62\",\n",
    "    \"t,\": \"\\u1E6D\", \"T,\": \"\\u1E6C\",\n",
    "    \".s\": \"\\u1E63\", \".S\": \"\\u1E62\",\n",
    "    \".t\": \"\\u1E6D\", \".T\": \"\\u1E6C\",\n",
    "    \"h,\": \"\\u1E2B\", \"H,\": \"\\u1E2A\",\n",
    "    \".h\": \"\\u1E2B\", \".H\": \"\\u1E2A\",\n",
    "}\n",
    "\n",
    "\n",
    "def normalize_ascii(text):\n",
    "    for old, new in ASCII_TO_DIACRITIC.items():\n",
    "        text = text.replace(old, new)\n",
    "    return text\n",
    "\n",
    "\n",
    "def normalize_gaps(text):\n",
    "    text = re.sub(r'\\[x\\]', '<gap>', text)\n",
    "    text = re.sub(r'\\[\\.{3,}[^\\]]*\\]', '<big_gap>', text)\n",
    "    text = re.sub(r'\\.{3,}', '<big_gap>', text)\n",
    "    text = re.sub(r'\\u2026', '<big_gap>', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def clean_akkadian(text):\n",
    "    if pd.isna(text) or not str(text).strip():\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    text = unicodedata.normalize(\"NFC\", text)\n",
    "    text = text.replace(\"!\", \"\").replace(\"?\", \"\")\n",
    "    text = re.sub(r'[\\u02F9\\u02FA]', '', text)\n",
    "    text = re.sub(r'\\[([^\\]]*)\\]', r'\\1', text)\n",
    "    text = normalize_ascii(text)\n",
    "    text = normalize_gaps(text)\n",
    "    text = text.translate(SUBSCRIPT_MAP)\n",
    "    text = re.sub(r'[/:.](?![\\d])', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Load Model\n",
    "# ============================================================\n",
    "print(f\"Loading model from {MODEL_PATH}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "model = T5ForConditionalGeneration.from_pretrained(MODEL_PATH)\n",
    "model = model.to(DEVICE)\n",
    "model.eval()\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Load Test Data\n",
    "# ============================================================\n",
    "test_df = pd.read_csv(os.path.join(COMP_DATA, \"test.csv\"))\n",
    "print(f\"Test data: {len(test_df)} rows\")\n",
    "print(test_df.head())\n",
    "\n",
    "# Preprocess\n",
    "test_df['clean_src'] = test_df['transliteration'].apply(clean_akkadian)\n",
    "print(f\"\\nSample cleaned:\")\n",
    "print(test_df[['transliteration', 'clean_src']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Generate Translations\n",
    "# ============================================================\n",
    "predictions = []\n",
    "\n",
    "for i in tqdm(range(0, len(test_df), BATCH_SIZE), desc=\"Translating\"):\n",
    "    batch_texts = [PREFIX + t for t in test_df['clean_src'].iloc[i:i+BATCH_SIZE]]\n",
    "    \n",
    "    inputs = tokenizer(\n",
    "        batch_texts,\n",
    "        return_tensors='pt',\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=MAX_SOURCE_LEN\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=MAX_TARGET_LEN,\n",
    "            num_beams=BEAM_WIDTH,\n",
    "            repetition_penalty=REP_PENALTY,\n",
    "            length_penalty=1.0,\n",
    "        )\n",
    "    \n",
    "    preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    predictions.extend(preds)\n",
    "\n",
    "print(f\"\\nGenerated {len(predictions)} translations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Create Submission\n",
    "# ============================================================\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'translation': predictions\n",
    "})\n",
    "\n",
    "# Ensure no NaN translations\n",
    "submission['translation'] = submission['translation'].fillna('')\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(\"Submission saved to submission.csv\")\n",
    "print(f\"Shape: {submission.shape}\")\n",
    "print(submission.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample translations\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  Sample Translations\")\n",
    "print(\"=\"*60)\n",
    "for i in range(min(5, len(test_df))):\n",
    "    print(f\"\\n--- Test {i} ---\")\n",
    "    print(f\"SRC: {test_df.iloc[i]['transliteration'][:200]}\")\n",
    "    print(f\"PRED: {predictions[i][:200]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}